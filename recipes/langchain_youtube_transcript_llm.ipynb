{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import langchain\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_BASE']=\"http://localhost:1234/v1\"\n",
    "os.environ['OPENAI_API_KEY']=\"local llm\"\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a different task than the one specified in the repository. Be sure to know what you're doing :)\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.llms.huggingface_hub import HuggingFaceHub\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import textwrap\n",
    "\n",
    "embeddings=HuggingFaceHubEmbeddings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_from_youtube_url(video_url):\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcript = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "\n",
    "    db=FAISS.from_documents(docs,embeddings) \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_query(db, query, k=4):\n",
    "    docs = db.similarity_search(query, k=k)\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "    llm = HuggingFaceHub(repo_id=\"HuggingFaceH4/zephyr-7b-alpha\",model_kwargs={\"max_new_tokens\":2000})\n",
    "    # llm=OpenAI()\n",
    "    # Template to use for the system message prompt\n",
    "    prompt = PromptTemplate(template=\"\"\"\n",
    "        You are a helpful assistant that that can answer questions about youtube videos \n",
    "        based on the video's transcript\n",
    "        \n",
    "        Answer the following question: {question}\n",
    "        By searching the following video transcript: {docs}\n",
    "        \n",
    "        Only use the factual information from the transcript to answer the question.\n",
    "        \n",
    "        If you feel like you don't have enough information to answer the question, say \"I don't know\".\n",
    "        \n",
    "        Your answers should be verbose and detailed.\n",
    "        \"\"\",input_variables=[\"question\",\"docs\"])\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    response = chain.run(question=query, docs=docs_page_content)\n",
    "    response = response.replace(\"\\n\", \"\")\n",
    "    return response, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        The question being asked is: what are they saying about Github Copilot?\n",
      "In the video, the speaker is discussing their experience using Github Copilot and\n",
      "comparing it to chat GPT. They mention that Github Copilot is faster to use for\n",
      "certain tasks, but they also mention that they have mixed results with it,\n",
      "particularly with the custom brush feature. They also mention that they want to\n",
      "explore the possibilities of using chat GPT and Github Copilot Labs for tackling a\n",
      "complete project. Overall, the speaker is providing a detailed and factual account of\n",
      "their experience using Github Copilot.\n"
     ]
    }
   ],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=th4j9JxWGko\"\n",
    "db = create_db_from_youtube_url(video_url)\n",
    "\n",
    "query = \"what are they saying about Github Copilot?\"\n",
    "response, docs = get_response_from_query(db, query)\n",
    "print(textwrap.fill(response, width=85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
